Index,Component,"Sub_Component","Field_Name","Field_Display_Name","Field_Description"
CIM,,,"access_count",,"The number of times the data model summary has been accessed since it was created."
CIM,,,"access_time",,"The timestamp of the most recent access of the data model summary."
CIM,,,"action_mode",,"Specifies whether the action was executed as an ad hoc action or from a saved search, based on whether a search_name exists."
CIM,,,"action_name",,"The name of the action."
CIM,,,"action_status",,"The status of the action. For example, ""success"", ""failure"", or ""pending""."
CIM,,,app,,"The app name which contains the view.
The application context in which the data model summary was accessed.
The app context in which the scheduled search was run.
The app ID of the app or add-on that owns the action."
CIM,,,buckets,,"The number of index buckets spanned by the data model acceleration summary."
CIM,,,"buckets_size",,"The total size of the bucket(s) spanned by the data model acceleration summary."
CIM,,,complete,,"The percentage of the data model summary that is currently complete."
CIM,,,component,,"The component of the modular action script involved in the event. Often used in conjunction with duration."
CIM,,,cron,,"The cron expression used to accelerate the data model."
CIM,,,datamodel,,"The name of the data model accelerated."
CIM,,,digest,,"A hash of the current data model constraints."
CIM,,,duration,,"How long the action took to complete, in milliseconds."
CIM,,,earliest,,"The earliest time that the data model summary was accessed."
CIM,,,"event_id",,"The unique event_id for the web service error event."
CIM,,,info,,"The action of the search (granted, completed, cancelled, failed)."
CIM,,,"is_inprogress",,"Indicates whether the data model acceleration is currently in progress."
CIM,,,"last_error",,"The text of the last error reported during the data model acceleration."
CIM,,,"last_sid",,"The search id of the last acceleration attempt."
CIM,,,latest,,"The most recent acceleration timestamp of the data model."
CIM,,,"mod_time",,"The timestamp of the most recent modification to the data model acceleration."
CIM,,,"orig_rid",,"The rid value of a source action result, automatically added to an event if it is the product of a previously executed action."
CIM,,,"orig_sid",,"The original sid value of a source action, automatically added to an event if it is the product of a previously executed action."
CIM,,,retention,,"The length of time that data model accelerations are retained, in seconds."
CIM,,,rid,,"The id associated with the result of a specific sid. By default, this is the row number of the search, starting with 0."
CIM,,,"savedsearch_name",,"The name of the saved search."
CIM,,,search,,"The search string."
CIM,,,"search_alias",,"Short description of the type of search being run, such as the name of the search or the name of the data model being accelerated."
CIM,,,"search_et",,"The earliest time of the search."
CIM,,,"search_lt",,"The latest time of the search."
CIM,,,"search_name",,"The name of the correlation search that triggered the action. Blank for ad hoc actions."
CIM,,,"search_type",,"The type of search."
CIM,,,sid,,"The search id."
CIM,,,sid,,"The search id, automatically assigned by splunkd."
CIM,,,signature,,"The logging string associated with alert action introspection events."
CIM,,,size,,"The amount of storage space the data model's acceleration summary takes up, in bytes."
CIM,,,source,,"The source associated with the search or scheduled search or the web service error occurred."
CIM,,,sourcetype,,"The source types included in the search or scheduled search or the web service error occurred."
CIM,,,spent,,"The amount of time spent loading the view (in milliseconds)."
CIM,,,"splunk_server",,"The Splunk Server on which the scheduled search runs."
CIM,,,status,,"The status of the scheduled search."
CIM,,,"summary_id",,"The unique id of the data model acceleration summary."
CIM,,,uri,,"The uniform resource identifier of the view activity."
CIM,,,user,,"The username of the user who accessed the view.
The name of the user who ran the search.
The user who scheduled the search.
The user who triggered an ad hoc alert. Not relevant for actions triggered by searches."
CIM,,,"user_bunit",,"The business unit of the user who ran the search."
CIM,,,"user_category",,"The category of the user who ran the search."
CIM,,,"user_priority",,"The priority of the user who ran the search."
CIM,,,view,,"The name of the view."
"General Help",,,"Indexed real-time search",,"aka ""rt indexed""
Use indexed real-time search when up-to-the-second accuracy is not needed"
"Search job inspector","Execution costs of dispatched searches",dispatch,"check_disk_usage",,"The time spent checking the disk usage of this job."
"Search job inspector","Execution costs of dispatched searches",dispatch,createdSearchResultInfrastructure,,"The time to create and set up the collectors for each peer and execute the HTTP post to each peer."
"Search job inspector","Execution costs of dispatched searches",dispatch,"earliest_time",,"Specifies the earliest time for this search. Can be a relative or absolute time. The default is an empty string."
"Search job inspector","Execution costs of dispatched searches",dispatch,"emit_prereport_files",,"When running a transforming search, Splunk Enterprise cannot compute the statistical results of the report until the search completes. After it fetches events from the search peers (dispatch.fetch), it, writes out the results to local files. dispatch.emit_prereport_files provides the time that it takes for Splunk Enterprise to write the transforming search results to those local files."
"Search job inspector","Execution costs of dispatched searches",dispatch,fetch,,"The time spent by the search head waiting for or fetching events from search peers. The dispatch.fetch value is different than the command.search value. The command.search value includes time spent by all indexers, which can be greater than the actual elapsed time of the search. If you have only a single node, then the dispatch.fetch and the command.search values will be similar. In a distributed environment, depending on the search, these values can be very different.
Time the SH spent waiting for the indexers to return."
"Search job inspector","Execution costs of dispatched searches",dispatch,finalWriteToDisk,,
"Search job inspector","Execution costs of dispatched searches",dispatch,localSearch,,
"Search job inspector","Execution costs of dispatched searches",dispatch,preview,,"The time spent generating preview results."
"Search job inspector","Execution costs of dispatched searches",dispatch,"process_remote_timeline",,"The time spent decoding timeline information generated by search peers."
"Search job inspector","Execution costs of dispatched searches",dispatch,readEventsInResults,,
"Search job inspector","Execution costs of dispatched searches",dispatch,reduce,,"The time spend reducing the intermediate report output."
"Search job inspector","Execution costs of dispatched searches",dispatch,timeline,,"The time spent generating the timeline and fields sidebar information."
"Search job inspector","Execution costs of dispatched searches",dispatch,writeStatus,,"The time spent periodically updating status.csv and info.csv in the job's dispatch directory."
"Search job inspector","Execution costs of dispatched searches","dispatch.evaluate",eval,,
"Search job inspector","Execution costs of dispatched searches","dispatch.evaluate",fields,,
"Search job inspector","Execution costs of dispatched searches","dispatch.evaluate",fillnull,,
"Search job inspector","Execution costs of dispatched searches","dispatch.evaluate",ifields,,
"Search job inspector","Execution costs of dispatched searches","dispatch.evaluate",inputlookup,,
"Search job inspector","Execution costs of dispatched searches","dispatch.evaluate",lookup,,
"Search job inspector","Execution costs of dispatched searches","dispatch.evaluate",outputlookup,,
"Search job inspector","Execution costs of dispatched searches","dispatch.evaluate",presort,,
"Search job inspector","Execution costs of dispatched searches","dispatch.evaluate",rename,,
"Search job inspector","Execution costs of dispatched searches","dispatch.evaluate",rex,,
"Search job inspector","Execution costs of dispatched searches","dispatch.evaluate",search,,"The time spent parsing the search and setting up the data structures needed to run the search. This component also includes the time it takes to evaluate and run subsearches. This is broken down further for each search command that is used. In general, dispatch.evaluate.<command_name> tells you the time spent parsing and evaluating the <command_name> argument. For example, dispatch.evaluate.search indicates the time spent evaluating and parsing the searchcommand argument."
"Search job inspector","Execution costs of dispatched searches","dispatch.evaluate",sort,,
"Search job inspector","Execution costs of dispatched searches","dispatch.evaluate",table,,
"Search job inspector","Execution costs of dispatched searches","dispatch.evaluate",tstats,,
"Search job inspector","Execution costs of dispatched searches","dispatch.fetch.rcp",phase0,,
"Search job inspector","Execution costs of dispatched searches","dispatch.stream",local,,"The time spent by search head on the streaming part of the search.
Time spent to retrieve data from the local event store."
"Search job inspector","Execution costs of dispatched searches","dispatch.stream",remote,,"The time spent executing the remote search in a distributed search environment, aggregated across all peers. Additionally, the time spent executing the remote search on each remote search peer is indicated with: dispatch.stream.remote.<search_peer_name>. output_count represents bytes sent rather than events in this case.
Time spent getting data from the indexers, as well as how much data was returned, cumulative."
"Search job inspector","Execution costs of dispatched searches","dispatch.stream.remote","<peer>",,"Per-peer breakout of dispatch.stream.remote."
"Search job inspector","Execution costs of dispatched searches",startup,handoff,,"The time elapsed between the forking of a separate search process and the beginning of useful work of the forked search processes. In other words it is the approximate time it takes to build the search apparatus. This is cumulative across all involved peers. If this takes a long time, it could be indicative of I/O issues with .conf files or the dispatch directory."
"Search job inspector","Execution costs of search commands",command,fields,,
"Search job inspector","Execution costs of search commands",command,ifields,,
"Search job inspector","Execution costs of search commands",command,inputlookup,,
"Search job inspector","Execution costs of search commands",command,outputlookup,,
"Search job inspector","Execution costs of search commands",command,presort,,
"Search job inspector","Execution costs of search commands",command,rex,,
"Search job inspector","Execution costs of search commands",command,"search.*",,"After the Splunk software identifies the events that contain the indexed fields matching your search, the events are analyzed to identify which events match the other search criteria. These are concurrent operations, not consecutive."
"Search job inspector","Execution costs of search commands",command,sort,,
"Search job inspector","Execution costs of search commands",command,table,,
"Search job inspector","Execution costs of search commands",command,timeliner,,
"Search job inspector","Execution costs of search commands","command.search",fieldalias,,"tells how long it took to rename fields based according to props.conf."
"Search job inspector","Execution costs of search commands","command.search",filter,,"tells how long it took to filter out events that do not match, for example fields and phrases.
This represents the amount of work done (time spent) to throw events away;
the gist is ""the index led me here, but the event doesn't match the search string"".
A lot of time spent here usually goes hand in hand with scanCount >> eventCount"
"Search job inspector","Execution costs of search commands","command.search","index.<...>",,"tells how long it took to look into the TSIDX files for the location to read in the raw data. This is the time spent identifying, from the tokens in the base search, what events to retrieve.
How much time was spent looking in the index files? A high proportion in the
""infinite time"" bucket (usec_2624544_INF) can indicate either a needle-in-haystack
search, or IO starvation."
"Search job inspector","Execution costs of search commands","command.search",kv,,"tells how long it took to apply field extractions to the events.command.
Performing KV extractions on the data. Cumulative across REPORT, EXTRACT,KV_MODE, AUTO_KV_JSON, etc."
"Search job inspector","Execution costs of search commands","command.search",lookups,,"tells how long it took to create new fields based on existing fields (perform field lookups).
TIme spent looking up fields in automatic or explicit lookups."
"Search job inspector","Execution costs of search commands","command.search",rawdata,,"tells how long it took to read the actual events from the rawdata files.
Uncompressing the raw data to retrieve events."
"Search job inspector","Execution costs of search commands","command.search",tags,,"tells how long it took to assign tags to events. Finding tags."
"Search job inspector","Execution costs of search commands","command.search",typer,,"tells how long it took to assign event types to events. Finding eventtypes."
"Search job inspector","Execution costs of search commands","command.search.expand_search",calcfield,,"Calculated fields - EVAL in props.conf"
"Search job inspector","Execution costs of search commands","command.search.expand_search",fieldaliaser,,
"Search job inspector","Execution costs of search commands","command.search.expand_search",kv,,
"Search job inspector","Execution costs of search commands","command.search.expand_search",lookup,,
"Search job inspector","Execution costs of search commands","command.search.expand_search",sourcetype,,
"Search job inspector","Execution costs of search commands",startup,configuration,,
"Search job inspector","Search job properties",command,eval,,"Actual evals in the search string"
"Search job inspector","Search job properties",command,fillnull,,
"Search job inspector","Search job properties",command,lookup,,
"Search job inspector","Search job properties",command,noop,,
"Search job inspector","Search job properties",command,rename,,
"Search job inspector","Search job properties",command,search,,
"Search job inspector","Search job properties",command,tstats,,
"Search job inspector","Search job properties","command.tstats","execute_input",,
"Search job inspector","Search job properties","command.tstats","execute_output",,
"Search job inspector","Search job properties","command.tstats","query_tsidx",,
"Search job inspector","Search job properties",dispatch,dispatchState,,"The state of the search. Can be any of QUEUED, PARSING, RUNNING, PAUSED, FINALIZING, FAILED, or DONE."
"Search job inspector","Search job properties",,"*",,"The Search job properties fields provide information about the search job. The Search job properties fields are listed in alphabetical order."
"Search job inspector","Search job properties",,canSummarize,,
"Search job inspector","Search job properties",,createTime,,
"Search job inspector","Search job properties",,cursorTime,,"The earliest time from which no events are later scanned. Can be used to indicate progress. See description for doneProgress."
"Search job inspector","Search job properties",,custom,,
"Search job inspector","Search job properties",,defaultSaveTTL,,
"Search job inspector","Search job properties",,defaultTTL,,
"Search job inspector","Search job properties",,delegate,,"For saved searches, specifies jobs that were started by the user. Defaults to scheduler."
"Search job inspector","Search job properties",,diskUsage,,"The total amount of disk space used, in bytes."
"Search job inspector","Search job properties",,doneProgress,,"A number between 0 and 1.0 that indicates the approximate progress of the search.doneProgress = (latestTime – cursorTime) / (latestTime – earliestTime)"
"Search job inspector","Search job properties",,dropCount,,"For real-time searches only, the number of possible events that were dropped due to the rt_queue_size (defaults to 100000)."
"Search job inspector","Search job properties",,"eai:acl",,"Describes the app and user-level permissions. For example, is the app shared globally, and what users can run or view the search?"
"Search job inspector","Search job properties",,earliestTime,,"The earliest time a search job is configured to start. Can be used to indicate progress. See description for doneProgress."
"Search job inspector","Search job properties",,eventAvailableCount,,"The number of events that are available for export."
"Search job inspector","Search job properties",,eventCount,,"The number of events returned by the search. In other words, this is the subset of scanned events (represented by the scanCount) that actually matches the search terms. (event_count)"
"Search job inspector","Search job properties",,eventFieldCount,,"The number of fields found in the search results."
"Search job inspector","Search job properties",,eventIsStreaming,,"Indicates if the events of this search are being streamed."
"Search job inspector","Search job properties",,eventIsTruncated,,"Indicates if events of the search have not been stored, and thus not available from the events endpoint for the search."
"Search job inspector","Search job properties",,eventSearch,,"Subset of the entire search that is before any transforming commands. The timeline and events endpoint represents the result of this part of the search."
"Search job inspector","Search job properties",,eventSorting,,"Indicates if the events of this search are sorted, and in which order. asc = ascending; desc = descending; none = not sorted"
"Search job inspector","Search job properties",,"field summary",,"Links to further information about your search. These links may not always be available"
"Search job inspector","Search job properties",,indexEarliestTime,,
"Search job inspector","Search job properties",,indexLatestTime,,
"Search job inspector","Search job properties",,isBatchMode,,"Indicates whether or not the search in running in batch mode. This applies only to searches that include transforming commands."
"Search job inspector","Search job properties",,isBatchModeSearch,,
"Search job inspector","Search job properties",,isDone,,"Indicates if the search has completed."
"Search job inspector","Search job properties",,isEventsPreviewEnabled,,
"Search job inspector","Search job properties",,isFailed,,"Indicates if there was a fatal error executing the search. For example, if the search string had invalid syntax."
"Search job inspector","Search job properties",,isFinalized,,"Indicates if the search was finalized (stopped before completion)."
"Search job inspector","Search job properties",,isPaused,,"Indicates if the search has been paused."
"Search job inspector","Search job properties",,isPreviewEnabled,,"Indicates if previews are enabled."
"Search job inspector","Search job properties",,isRealTimeSearch,,"Indicates if the search is a real time search."
"Search job inspector","Search job properties",,isRemoteTimeline,,"Indicates if the remote timeline feature is enabled."
"Search job inspector","Search job properties",,isSaved,,"Indicates that the search job is saved, storing search artifacts on disk for 7 days from the last time that the job has been viewed or touched. Add or edit the default_save_ttl value in limits.conf to override the default value of 7 days."
"Search job inspector","Search job properties",,isSavedSearch,,"Indicates if this is a saved search run using the scheduler."
"Search job inspector","Search job properties",,isTimeCursored,,"Specifies if the cursorTime can be trusted or not. Typically this parameter it set to true if the first command is search."
"Search job inspector","Search job properties",,isZombie,,"Indicates if the process running the search is dead, but with the search not finished."
"Search job inspector","Search job properties",,keywords,,"All positive keywords used by this search. A positive keyword is a keyword that is not in a NOT clause."
"Search job inspector","Search job properties",,label,,"Custom name created for this search."
"Search job inspector","Search job properties",,latestTime,,"The latest time a search job is configured to start. Can be used to indicate progress. See description for doneProgress."
"Search job inspector","Search job properties",,messages,,"Errors and debug messages."
"Search job inspector","Search job properties",,modifiedTime,,
"Search job inspector","Search job properties",,normalizedSearch,,"Ultra-­‐verbose stage of search assembly
When you use the search or where command in a search string, the SPL processor might reorder the expression statement that follows the command for normalization purposes. The SPL processor applies two kinds of normalization logic to search strings: predicate flip and predicate sort.
For more information about predicates and predicate-based search optimization, see Built-in optimization.
Use the Job Inspector to see the results of search normalization and optimization. See Analyze search optimizations.
The search string, as interpreted by the parser. This includes reverse lookups from enrichment, tags, eventtypes, etc"
"Search job inspector","Search job properties",,numPreviews,,"Number of previews that have been generated so far for this search job."
"Search job inspector","Search job properties",,optimizedSearch,,"The restructured syntax for the search that was run. The built-in optimizers analyze your search and restructure the search syntax, where possible, to improve search performance. The search that you ran is displayed under the search job property."
"Search job inspector","Search job properties",,performance,,"This is another representation of the Execution costs."
"Search job inspector","Search job properties",,phase0,,
"Search job inspector","Search job properties",,phase1,,
"Search job inspector","Search job properties",,pid,,"Process ID."
"Search job inspector","Search job properties",,priority,,"lets you improve the the run priority of a deferred scheduled report. This means that it may run ahead of other reports, and may have a better chance of running on or near its scheduled run time."
"Search job inspector","Search job properties",,provenance,,"One of the following search sources: cli, rest, ui:<App>:<View>"
"Search job inspector","Search job properties",,remoteSearch,,"The search string that is sent to every search peer.
The part of the search run on the indexers, sometimes called the ""map part"""
"Search job inspector","Search job properties",,reportSearch,,"If reporting commands are used, the reporting search.
The remainder of the search, run locally on the SH, sometimes called the ""reduce part"""
"Search job inspector","Search job properties",,request,,"GET arguments that the search sends to splunkd."
"Search job inspector","Search job properties",,resultCount,,"The total number of results returned by the search. For generating commands such as | rest, this is the number of rows produced. (result_count)"
"Search job inspector","Search job properties",,resultIsStreaming,,"Indicates if the final results of the search are available using streaming (for example, no transforming operations)."
"Search job inspector","Search job properties",,resultPreviewCount,,"The number of result rows in the latest preview results."
"Search job inspector","Search job properties",,runDuration,,"Time in seconds that the search took to complete."
"Search job inspector","Search job properties",,runtime,,"Time in seconds that the search took to complete."
"Search job inspector","Search job properties",,sampleRatio,,
"Search job inspector","Search job properties",,sampleSeed,,
"Search job inspector","Search job properties",,scanCount,,"The number of events that are scanned or read off disk. The number of events found in the index based on keywords in the search
For tstats searches, this is the number of events in the matching tsidx files. (scan_count)"
"Search job inspector","Search job properties",,search,,"The search string."
"Search job inspector","Search job properties",,"search.log",,"Links to further information about your search. These links may not always be available"
"Search job inspector","Search job properties",,searchCanBeEventType,,"If the search can be saved as an event type, this will be 1, otherwise, 0.Only base searches (no subsearches or pipes) can be saved as event types."
"Search job inspector","Search job properties",,searchEarliestTime,,
"Search job inspector","Search job properties",,searchLatestTime,,"The latest time a search job is configured to start."
"Search job inspector","Search job properties",,searchProviders,,"A list of all the search peers that were contacted."
"Search job inspector","Search job properties",,searchTotalBucketsCount,,"How many indexing buckets were searched. (searched_buckets)"
"Search job inspector","Search job properties",,searchTotalEliminatedBucketsCount,,"How many of those that were eliminated (usually by bloom filters). (eliminated_buckets)"
"Search job inspector","Search job properties",,sid,,"The search ID number."
"Search job inspector","Search job properties",,"slices decompressed",,"How many index slices (usually 128kB) were decompressed. (decompressed_slices)"
"Search job inspector","Search job properties",,"slices examined",,"(total_slices)"
"Search job inspector","Search job properties",,statusBuckets,,"Maximum number of timeline buckets."
"Search job inspector","Search job properties",,timeline,,"Links to further information about your search. These links may not always be available"
"Search job inspector","Search job properties",,ttl,,"The time to live, or time before the search job expires after it completes."
"Search job inspector","Search job properties",,"workload_pool",,
"_audit",audittrail,,"Search_StartUp_Time_Average_Time(ms)",,"Average time for preprocessing before search startup. Counted from time search state is set to RUNNING."
"_audit",audittrail,,"Search_StartUp_Time_Max_Time(ms)",,"Maximum time for preprocessing before search startup. Counted from time search state is set to RUNNING."
"_audit",audittrail,,"_time",Time,"The time that the search was started."
"_audit",audittrail,,"api_et",,"The earliest time of the API call, which is the earliest time for which events were requested. Time range passed down from API args, before any search-based time modifiers"
"_audit",audittrail,,"api_lt",,"The latest time of the API call, which is the latest time for which events were requested. Time range passed down from API args, before any search-based time modifiers"
"_audit",audittrail,,"available_count","Available Count","The number of events that are available for export."
"_audit",audittrail,,"considered_events","Considered Events","Total events in considered buckets (searched - eliminated)."
"_audit",audittrail,,datamodel,Datamodel,"Derived from savedsearch_name"
"_audit",audittrail,,"decompressed_slices","Decompressed Slices","How many slices were decompressed to fetch the raw events from (i.e., after searching in tsidx, we know exactly which slices to decompress to get the raw events). The larger the difference between this field and total_slices, the sparser the search. Slices: Collection of compressed (gzipped) blocks, called slices,
Concatenated together in a rawdata/journal.gz
Think “cat chunkA.gzchunkB.gz...chunkN.gz> journal.gz”).
Slices contain the actual raw events.
Pool of concatenated slices allows be seeked into
Locations offsets are pointed to by the values array pointers in tsidx.
Such organization allows us to zoom in to the right slice
reduces the amount of decompression time & volume compared to having a single, massive rawdatafile."
"_audit",audittrail,,"drop_count",,"In real-time searches only, the number of possible events dropped due to queue size."
"_audit",audittrail,,"eliminated_buckets","Eliminated Buckets","Buckets eliminated by bloom filter (we never looked at tsidx index). The more buckets eliminated, the sparser the search. See http://docs.splunk.com/Documentation/Splunk/latest/Search/Aboutsearch for more information about types of searches. How many of those that were eliminated (usually by bloom filters)."
"_audit",audittrail,,"event_count","Event Count","Number of events that were returned by the ""search"" command based on matched search terms.
This is the number of events that matched the search criteria
If the search retrieved or generated events, the count of events returned with the search."
"_audit",audittrail,,"exec_time","Dispatch Time","The execution time of the search in integer quantity of seconds into the Unix epoch.
Timestamp of start of search"
"_audit",audittrail,,info,Info,"The status of the search."
"_audit",audittrail,,"is_realtime","IS Realtime","Indicates whether the search was real-time (1) or historical (0)."
"_audit",audittrail,,"result_count","Result Count","If the search is a transforming search, the count of results for the search."
"_audit",audittrail,,roles,Roles,
"_audit",audittrail,,"savedsearch_name","Savedsearch Name","The name of the saved search."
"_audit",audittrail,,"scan_count","Scan Count","Number of events scanned (decompressed and evaluated against search terms). Measured before the first filter in the search pipeline. The only events filtered from here are filtered by index. Under certain circumstances, this can be > event_count. The number of events retrieved from a Splunk index at a low level."
"_audit",audittrail,,search,Search,"The search string."
"_audit",audittrail,,"search_et","Search ET","The earliest time set for the search to run.
Time range as modified by initial search operator."
"_audit",audittrail,,"search_id","Search ID","The search job ID.
The prefix is meaningful - it can distinguish ad hoc from scheduled searches, etc
remote_<SH> --> Remote Marker
rt_ --> Real Time Marker
subsearch_ --> Subsearch Marker
rsa_ --> Replica Marker
md_ --> Metadata Marker
ta_ --> Typeahead Marker"
"_audit",audittrail,,"search_lt","Search LT","The latest time set for the search to run.
Time range as modified by initial search operator."
"_audit",audittrail,,"search_startup_time","Search Startup Time","Startup time indicates that parsing is complete and the distributed search infrastructure is set up. At startup, Splunk software is ready to wait for responses from indexers."
"_audit",audittrail,,"searched_buckets","Searched Buckets","Buckets in the time range. How many indexing buckets were searched."
"_audit",audittrail,,"splunk_server",,"The host name of the machine where the search was run."
"_audit",audittrail,,"total_run_time","Total Run Time","Search run time in seconds. The total time it took to run the search in seconds."
"_audit",audittrail,,"total_slices","Total Slices","How many slices in all considered buckets Journal.gz that might need to be decompressed. Total slices examined during the search"
"_internal",scheduler,,"_time",Time,"The time that the search was started."
"_internal",scheduler,,"alert_actions","Alert Actions","The Alert or Trigger Action performed when the Trigger condition is meet. Examples:
email,logevent,lookup,outputtelemetry,script
logevent,lookup,outputtelemetry
outputtelemetry
populate_lookup"
"_internal",scheduler,,app,App,"App name"
"_internal",scheduler,,"concurrency_category","Concurrency Category","One of :
historical
historical_scheduled
real-time
real-time_scheduled
summarization"
"_internal",scheduler,,"concurrency_context","Concurrency Context","One of:
Instance-wide - auto-summary
Instance-wide - historical
Instance-wide - real-time
Instance-wide - scheduled historical
Instance-wide - scheduled real-time
Instance-wide, search-based
Role-based - historical
Role-based - real-time
SHC-wide - auto-summary
SHC-wide - historical
SHC-wide - real-time
SHC-wide - scheduled historical
SHC-wide - scheduled real-time
SHC-wide, search-based
SHC-wide, user-based - historical
SHC-wide, user-based - real-time
User-based - real-time"
"_internal",scheduler,,"concurrency_limit","Concurrency Limit",
"_internal",scheduler,,"dispatch_time","Dispatch Time","The execution time of the savedsearch in integer quantity of seconds into the Unix epoch."
"_internal",scheduler,,priority,Priority,"lets you improve the the run priority of a deferred scheduled report. This means that it may run ahead of other reports, and may have a better chance of running on or near its scheduled run time."
"_internal",scheduler,,reason,Reason,"The maximum disk usage quota for this user has been reached
The maximum disk usage quota for this user on this cluster has been reached
The maximum number of concurrent auto-summarization searches on this cluster has been reached
The maximum number of concurrent auto-summarization searches on this instance has been reached
The maximum number of concurrent historical scheduled searches on this cluster has been reached
The maximum number of concurrent historical scheduled searches on this instance has been reached
The maximum number of concurrent historical searches for this role has been reached
The maximum number of concurrent historical searches for this user based on their role quota has been reached
The maximum number of concurrent historical searches for this user on this cluster based on their role quota has been reached
The maximum number of concurrent historical searches on this cluster has been reached
The maximum number of concurrent historical searches on this instance has been reached
The maximum number of concurrent real-time scheduled searches on this cluster has been reached
The maximum number of concurrent real-time scheduled searches on this instance has been reached
The maximum number of concurrent real-time searches for this role has been reached
The maximum number of concurrent real-time searches for this user based on their role quota has been reached
The maximum number of concurrent real-time searches for this user on this cluster based on their role quota has been reached
The maximum number of concurrent real-time searches on this cluster has been reached
The maximum number of concurrent real-time searches on this instance has been reached
The maximum number of concurrent running jobs for this historical scheduled search on this cluster has been reached
The maximum number of concurrent running jobs for this real-time scheduled search on this cluster has been reached
The maximum number of concurrent running jobs for this search on this cluster has been reached
The maximum number of concurrent running jobs for this search on this instance has been reached
The maximum number of concurrent scheduled searches has been reached
The maximum number of concurrent searches has been reached for all roles"
"_internal",scheduler,,"result_count","Result Count","Number of events returned on search head. For reporting searches, this can be different from event_count. For example:
index=_internal | stats count
will have an event_count equal to the number of events matched but a result_count of 1, given that the result of this search is only one row. The number of resulting rows.
If the search is a transforming search, the count of results for the search."
"_internal",scheduler,,"run_time","Total Run Time","The total time it took to run the search in seconds."
"_internal",scheduler,,"savedsearch_id","Savedsearch ID","The Splunk ID of the saved search."
"_internal",scheduler,,"savedsearch_name","Savedsearch Name","The name of the saved search."
"_internal",scheduler,,"scheduled_time","Scheduled Time","Scheduled Time"
"_internal",scheduler,,"search_type","Search Type","Derived from search_type, savedsearch_name, alert_actions & search_id"
"_internal",scheduler,,sid,"Search ID","Search ID (SID)."
"_internal",scheduler,,"skipped_count","Skipped Count","How many time the savedsearch/datamodel acceleration/report acceleration skipped"
"_internal",scheduler,,status,info,"The status of the scheduled search."
"_internal",scheduler,,user,User,"The user who scheduled the search."
"_internal",scheduler,,"window_time","Window Time","specifies how long the report scheduler can delay a report from running and allow higher-priority reports to run ahead ahead of it."
"_internal","splunkd_remote_searches",,elapsedTime,,"The amount of time the indexer spent working on this search. Includes time spent waiting for search head to receive data, so not exactly the time spent working, but it's the closest thing we have."
"_introspection","splunk_resource_usage",data,elapsed,"Total Run Time","Elapsed wall time, accurate to within the collection period."
"_introspection","splunk_resource_usage",data,"fd_used","FD Used","Number of currently open files used by this process."
"_introspection","splunk_resource_usage",data,"mem_used","Memory Used","Current amount of resident physical memory used (KB). (Usually far less deceiving than virtual memory because operating systems can be liberal with virtual memory size but never with resident memory size.) On Windows, mem_used is obtained by reading the WorkingSetSize property returned by the GetProcessMemoryInfo() function (see GetProcessMemoryInfo function and PROCESS_MEMORY_COUNTERS structure)."
"_introspection","splunk_resource_usage",data,"normalized_pct_cpu","Normalized CPU %","Percentage of CPU usage across all cores. 100% is equivalent to all CPU resources on the machine."
"_introspection","splunk_resource_usage",data,"page_faults","Page Faults","Number of major page faults. Extra field."
"_introspection","splunk_resource_usage",data,"pct_cpu","CPU %","Percentage of CPU usage, relative to one core. 100% is equivalent to 1 core."
"_introspection","splunk_resource_usage",data,"pct_memory","Memory %","Percentage of physical memory used hostwide ((mem_used/available_host_memory) * 100)."
"_introspection","splunk_resource_usage",data,pid,PID,"Process ID."
"_introspection","splunk_resource_usage",data,ppid,,"Parent process ID. Not available for all processes."
"_introspection","splunk_resource_usage",data,process,,"Process name. The .exe suffix is stripped on Windows operating systems."
"_introspection","splunk_resource_usage",data,"read_mb","Read MB","Amount of data read (MB), excluding cache reads."
"_introspection","splunk_resource_usage",data,"scan_count","Scan Count","Event scan count for running process. Available only in Linux systems. This property is offered experimentally and might be changed or removed in a future release. Number of events scanned (decompressed and evaluated against search terms). Measured before the first filter in the search pipeline. The only events filtered from here are filtered by index."
"_introspection","splunk_resource_usage",data,status,,"Status from the OS scheduler. Can be R (runnable or running), W (waiting), stopped, Z (zombie), or O (other). W includes voluntary sleep or blocking on I/O. O means status is knowable but does not fit into one of those categories. Not available on Windows."
"_introspection","splunk_resource_usage",data,"t_count",,"Current number of threads."
"_introspection","splunk_resource_usage",data,"written_mb","Written MB","Amount of data written (MB), excluding canceled writes."
"_introspection","splunk_resource_usage","data.search_props","acceleration_id","Acceleration ID","Data Model or Reporting Acceleration Acceleration ID"
"_introspection","splunk_resource_usage","data.search_props",app,App,"App name"
"_introspection","splunk_resource_usage","data.search_props","delta_scan_count","Delta Scan Count","Delta event scan count for running process. Available only in Linux systems. This property is offered experimentally and might be changed or removed in a future release."
"_introspection","splunk_resource_usage","data.search_props",label,"Savedsearch Name","Human-readable label for the saved search."
"_introspection","splunk_resource_usage","data.search_props",mode,"Search Mode","One of the following search modes.
historical
historical batch
RT
RT indexed (indexed Realtime mode)"
"_introspection","splunk_resource_usage","data.search_props",provenance,Provenance,"One of the following search sources: cli, rest, ui:<App>:<View>"
"_introspection","splunk_resource_usage","data.search_props",role,,"Splunk Enterprise platform role. Either head or peer."
"_introspection","splunk_resource_usage","data.search_props","search_head","Search Head","Dispatching search head for processes running saved searches."
"_introspection","splunk_resource_usage","data.search_props",sid,"Search ID","Search ID (SID)."
"_introspection","splunk_resource_usage","data.search_props",type,"Search Type","One of the following search types. ad-hoc datamodel acceleration other report acceleration scheduled summary indexing"
"_introspection","splunk_resource_usage","data.search_props",user,User,"Splunk username who initiated the search"
"_introspection","splunk_resource_usage",,"_time",Time,"The time that the search was started."
"_introspection","splunk_resource_usage",,args,,"Non-search process arguments."
"_introspection","splunk_resource_usage",,"cpu_system_time",,"Cumulative time this process has spent executing in kernel (incl. system calls). Extra field."
"_introspection","splunk_resource_usage",,"cpu_user_time",,"Cumulative time this process has spent executing in user space (incl. library functions). Extra field."
"_introspection","splunk_resource_usage",,"mem_unshared_data_used",,"Amount of heap and stack used. Not available on Windows. Extra field."
"savedsearches.conf",,,"alert_severity",,
"savedsearches.conf",,,"alert_track",,
"savedsearches.conf",,,"alert_type",,
"savedsearches.conf",,,"allow_skew",,"allow_skew = <percentage>|<duration-specifier>
* Lets the search scheduler randomly distribute scheduled searches more evenly over the scheduled time periods.
* When set to non-zero for searches with the following cron_schedule values, the search scheduler randomly ""skews"" the second, minute, and hour that the search actually runs on: * * * * * Every minute. */M * * * * Every M minutes (M > 0). 0 * * * * Every hour. 0 */H * * * Every H hours (H > 0). 0 0 * * * Every day (at midnight).
* When set to non-zero for a search that has any other 'cron_schedule' setting, the search scheduler can only randomly skew the second that the search runs on.
* The amount of skew for a specific search remains constant between edits of the search.
* To specify a percentage: Use an integer value followed by the percent '%' symbol. This specifies the maximum amount of time to skew, as a percentage of the scheduled search period.
* To specify a duration: Use <integer><timescale> to specify a maximum duration. Supported units are: m, min, minute, mins, minutes h, hr, hour, hrs, hours d, day, days The <timescale> is required and can be omitted only when <integer> is 0.
* Skew examples: 100% (For an every-5-minute search = 5 minutes maximum) 50% (For an every-1-minute search = 30 seconds maximum) 5m = 5 minutes maximum 1h = 1 hour maximum
* A value of 0 does not allow a skew to occur.
* Default: 0"
"savedsearches.conf",,,"auto_summarize",,
"savedsearches.conf",,,"cron_schedule",,
"savedsearches.conf",,,"max_concurrent",,"max_concurrent = <unsigned integer>
* The maximum number of concurrent instances of this search that the scheduler is allowed to run.
* Default: 1"
"savedsearches.conf",,,"next_scheduled_time",,
"savedsearches.conf",,,"realtime_schedule",,"realtime_schedule = [0|1]
* Controls the way the scheduler computes the next run time of a scheduled search.
* If set to 1, the scheduler determines the next scheduled search run time based on the current time. * NOTE: When set to 1, the scheduler might skip some execution periods to make sure that the scheduler is executing the searches that are running over the most recent time range.
* If set to 0, the scheduler determines the next scheduled search run time based on the last run time for the search. This is called continuous scheduling. * NOTE: When set to 0, the scheduler never skips scheduled execution periods. However, the execution of the saved search might fall behind depending on the scheduler's load. * Use continuous scheduling whenever you enable the 'summary index' option.
* The scheduler tries to run searches that have 'realtime_schedule' set to 1 before it runs searches that have continuous scheduling (realtime_schedule = 0).
* Default: 1"
"savedsearches.conf",,,removable,,
"savedsearches.conf",,,"run_n_times",,"run_n_times = <unsigned integer>
* Runs this search exactly the specified number of times. The search is not run again until the Splunk platform is restarted.
* Default: 0 (infinite)."
"savedsearches.conf",,,"savedsearch_type",,
"savedsearches.conf",,,"schedule_priority",,"schedule_priority = [default | higher | highest]
* Raises the scheduling priority of a search: * When set to ""default"", specifies that there is no increase to the scheduling priority. * When set to ""higher"", specifies that the scheduling priority is higher than other searches of the same scheduling tier. While there are four tiers of priority for scheduled searches, only the following are affected by this setting: 1. Real-Time-Scheduled (realtime_schedule=1). 2. Continuous-Scheduled (realtime_schedule=0). * When set to ""highest"", specifies that the scheduling priority is higher than other searches regardless of scheduling tier. However, real-time-scheduled searches with 'schedule_priority = highest' always have priority over continuous scheduled searches with 'schedule_priority = highest'. * The high-to-low order is: RTSS(H) > CSS(H) > RTSS(h) > RTSS(d) > CSS(h) > CSS(d) Where: RTSS = real-time-scheduled search CSS = continuous-scheduled search d = default h = higher H = highest
* The scheduler honors a non-default priority only when the search owner has the 'edit_search_schedule_priority' capability. * A non-default priority is mutually exclusive with a non-zero 'schedule_window' (see below). If a user specifies both for a scheduled search, the scheduler honors the priority only. * However, if a user specifies both settings for a search, but the search owner does not have the 'edit_search_scheduler_priority' capability, then the scheduler ignores the priority setting and honors the 'schedule_window'.
* CAUTION: Having too many searches with a non-default priority will impede the ability of the scheduler to minimize search starvation. Use this setting only for mission-critical searches.
* Default: default"
"savedsearches.conf",,,"schedule_window",,"schedule_window = <unsigned integer> | auto
* When schedule_window is non-zero, it indicates to the scheduler that the search does not require a precise start time. This gives the scheduler greater flexibility when it prioritizes searches.
* When 'schedule_window' is set to an integer greater than 0, it specifies the ""window"" of time (in minutes) that a search may start within. * The 'schedule_window' must be shorter than the period of the search. * Schedule windows are not recommended for searches that run every minute.
* When set to 0, there is no schedule window. The scheduler starts the search as close to its scheduled time as possible.
* When set to ""auto,"" the scheduler calculates the 'schedule_window' value automatically. * For more information about this calculation, see the search scheduler documentation.
* A non-zero 'schedule_window' is mutually exclusive with a non-default 'schedule_priority'. See 'schedule_priority' for details.
* Default: 0 for searches that are owned by users with the 'edit_search_schedule_window' capability. For these searches, this value can be changed.
* Default: auto for searches that are owned by users that do not have the 'edit_search_window' capability. For these searches, this setting cannot be changed."
"savedsearches.conf",,,"scheduled_times",,
"GMC Lookups","asset_lookup_by_cidr","assets_by_cidr.csv",,,GMC
"GMC Lookups","asset_lookup_by_str","assets_by_str.csv",,,GMC
"GMC Lookups","splunk_all_rest_server_info_csv_lookup","splunk_all_rest_server_info_csv.csv",,,GMC
"GMC Lookups","splunk_fields_lookup","splunk_fields.csv",,,GMC
"GMC Lookups","splunk_ports_lookup","splunk_ports.csv",,,GMC
"GMC Lookups","splunk_sh_admin_search_concurrency_settings_handler_csv_lookup","splunk_sh_admin_search_concurrency_settings_handler_csv.csv",,,GMC
"GMC Lookups","splunk_sh_audit_savedsearch_activity_kv_store_lookup",,,,GMC
"GMC Lookups","splunk_sh_configs_conf_props_rest_csv_lookup","splunk_sh_configs_conf_props_rest_csv.csv",,,GMC
"GMC Lookups","splunk_sh_identities_lookup","splunk_sh_identities_csv.csv",,,GMC
"GMC Lookups","splunk_sh_index_audit_user_login_kv_store_lookup",,,,GMC
"GMC Lookups","splunk_sh_index_internal_scheduler_jobs_kv_store_lookup",,,,GMC
"GMC Lookups","splunk_sh_rest_admin_lookup_table_files_kv_store_lookup",,,,GMC
"GMC Lookups","splunk_sh_rest_admin_transforms_lookup_csv_lookup","splunk_sh_rest_admin_transforms_lookup_csv.csv",,,GMC
"GMC Lookups","splunk_sh_rest_data_indexes_csv_lookup","splunk_sh_rest_data_indexes_csv.csv",,,GMC
"GMC Lookups","splunk_sh_rest_data_inputs_all_csv_lookup","splunk_sh_rest_data_inputs_all_csv.csv",,,GMC
"GMC Lookups","splunk_sh_rest_data_macros_csv_lookup","splunk_sh_rest_data_macros_csv.csv",,,GMC
"GMC Lookups","splunk_sh_rest_data_models_csv_lookup","splunk_sh_rest_data_models_csv.csv",,,GMC
"GMC Lookups","splunk_sh_rest_data_props_calcfields_csv_lookup","splunk_sh_rest_data_props_calcfields_csv.csv",,,GMC
"GMC Lookups","splunk_sh_rest_data_props_extractions_csv_lookup","splunk_sh_rest_data_props_extractions_csv.csv",,,GMC
"GMC Lookups","splunk_sh_rest_data_props_fieldaliases_csv_lookup","splunk_sh_rest_data_props_fieldaliases_csv.csv",,,GMC
"GMC Lookups","splunk_sh_rest_data_props_lookups_csv_lookup","splunk_sh_rest_data_props_lookups_csv.csv",,,GMC
"GMC Lookups","splunk_sh_rest_data_transforms_extractions_csv_lookup","splunk_sh_rest_data_transforms_extractions_csv.csv",,,GMC
"GMC Lookups","splunk_sh_rest_data_ui_dashboards_lookup",,,,GMC
"GMC Lookups","splunk_sh_saved_searches_rest_kv_store_lookup",,,,GMC
"GMC Lookups","splunk_sh_web_access_kv_store_lookup",,,,GMC
